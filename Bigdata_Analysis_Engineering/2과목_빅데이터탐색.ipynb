{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79995ab",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "## 데이터 정제 \n",
    "\n",
    "### 데이터 정제 \n",
    "\n",
    "1. 데이터 전처리의 중요성\n",
    "    - 데이터 전처리는 반드시 거쳐야 하는 과정이다.\n",
    "    - 분석 결과에 직접적인 영향을 주고 있어 반복적으로 수행해야 한다.\n",
    "    - 가장 많은 시간이 소요되는 단계이다. 데이터 정제 -> 결측값 처리 -> 이상값 처리 -> 분석변수 처리 순서로 진행된다.\n",
    "\n",
    "\n",
    "2. 데이터 정제(Data Cleansing)\n",
    "    - 결측값을 채우거나 이상값을 제거하는 과정을 통해 데이터의 신뢰도를 높이는 작업\n",
    "\n",
    "\n",
    "3. 데이터 정제 절차\n",
    "    - 데이터 오류 원인 분석\n",
    "        - 결측값 : 필수적인 데이터가 입력되지 않고 누락된 값 -> 중심 경향값 넣기(평균값, 중위수, 최빈수), 분포기반 처리\n",
    "        - 노이즈 : 실제는 입력되지 않았지만 입력되었다고 잘못 판단된 값 -> 일정간격으로 이동하면서 주변보다 높거나 낮으면 평균값, 중간값 대체\n",
    "        - 이상값 : 데이터의 범위에서 많이 벗어난 아주 작은 값이나 아주 큰 값 -> 하한보다 낮으면 하한값 대체, 상한보다 높으면 상한값 대체\n",
    "    - 데이터 정제 대상 선정\n",
    "        - 모든 데이터를 대상으로 정제활동을 한다.\n",
    "        - 데이터 품질 저하의 위험이 있는 데이터에 대해서는 더 많은 정제 활등을 수행한다.\n",
    "        - 내부데이터 보다는 외부데이터, 비정형 반정형에 대해 데이터 정제를 수행한다.\n",
    "    - 데이터 정제 방법 결정\n",
    "        - 삭제 : 오류 데이터에 대해 전체 또는 부분삭제, 무작위적인 삭제는 데이터 활용의 문제를 야기함.\n",
    "        - 대체 : 오류 데이터를 평균값, 최빈수, 중위수로 대체, 왜곡의 문제를 일으킬 수 있음.\n",
    "        - 예측값 삽입 : 회귀식 등을 이용한 예측값을 생성하여 삽입. 정상 데이터 구간에 대해서도 회귀식이 잘 성립되어야 함.\n",
    "    - 데이터 일관성 유지를 위한 정제 기법(외부 데이터에 대한 일관성 부여)\n",
    "        - 변환(Transform) : 다양한 형태로 표현한 값을 일관된 형태로 변환.\n",
    "        - 파싱(Parsing) : 정제 규칙을 적용하기 위한 유의미한 최소 단위로 분할하는 작업.\n",
    "        - 보강(Entrancement) : 변환, 파싱, 수정, 표준화 등을 통한 추가 정보를 반영하는 작업.\n",
    "\n",
    "\n",
    "4. 데이터 세분화 : 데이터를 기준에 따라 나누고, 선택한 매개변수를 기반으로 유사한 데이터를 그룹화 하여 효율적으로 사용함.\n",
    "\n",
    "\n",
    "5. 데이터 세분화 방법\n",
    "    - 계층적 방법 : 사전에 군집수를 정하지 않고 단계적으로 단계별 군집결과를 산출함.\n",
    "        - 응집분석법 : 각 객체를 하나의 소집단으로 간주하여 단계적으로 합침\n",
    "        - 분할분석법 : 전체 집단으로부터 시작하여 유사성이 떨어지는 객체들을 분리\n",
    "    - 비 계층적 방법 : 군집을 위한 소집단의 개수를 정해놓고 각 객체 중 하나의 소집단으로 배정함.\n",
    "        - 인공신경망 모델 : 통계학적 학습 모델\n",
    "        - K-means 군집 : K 소집단의 중심좌표를 이용하여 거리를 중심으로 소집단을 배정하여 중심좌표를 업데이트 함.\n",
    "        \n",
    "### 데이터 결측값 처리 \n",
    "\n",
    "1. 데이터 결측값(Missing Value) 개념\n",
    "    - 입력이 누락된 값. NA, Null, Inf 등으로 표현한다.\n",
    "\n",
    "\n",
    "2. 데이터 결측값 종류\n",
    "    - 완전 무작위 결측(MCAR) : 변수상에서 발생한 결측값이 다른 변수들과 아무런 상관이 없는 경우\n",
    "    - 무작위 결측(MAR) : 누락된 자료가 특정 변수와 관련되어 일어나지만, 그 변수의 결과는 관계가 없는 경우(필요조건)\n",
    "    - 비 무작위 결측(MNAR) : 누락된 값이 다른 변수와 연관 있는경우(필요충분조건)\n",
    "\n",
    "\n",
    "3. 데이터 결측값 처리 절차\n",
    "    - 결측값 식별\n",
    "    - 결측값 부호화\n",
    "        - NA : 기록되지 않은 값\n",
    "        - NaN : 수학적으로 정의되지 않은 값\n",
    "        - Inf : 무한대\n",
    "        - Null : 값이 없음\n",
    "    - 결측값 대체 : 알고리즘을 통해 결측값을 처리\n",
    "\n",
    "\n",
    "4. 데이터 결측값 처리 방법\n",
    "    - 단순대치법\n",
    "        - 완전 분석법 : 불완전 자료는 모두 무시하고 완전하게 관측된 자료만 사용하여 분석.\n",
    "        - 평균 대치법 : 관측 또는 실험되어 얻어진 자료의 평균값으로 결측값을 대치함.\n",
    "            - 비 조건부 평균 대치법 : 단순 평균\n",
    "            - 조건부 평균 대치법 : 회귀분석 모델의 가중치 적용\n",
    "        - 단순 확률 대치법 : 평균 대치법에서 결측값을 대치할 때 적절한 확률값을 부여한 후 대치함.\n",
    "            - 핫덱(Hot-Deck) 대체 : 무응답을 현재 진행 중인 연구에서 '비슷한' 성향을 가진 응답자의 자료로 대체하는 방법\n",
    "            - 콜드덱(Cold-Deck) 대체 : 외부 출처 또는 이전의 연구에서 가져오는 방법\n",
    "            - 혼합방법\n",
    "    - 다중 대치법 : 단순 대치법을 m번 대치를 통해 m개의 가상적 완전한 자료를 만들어서 분석, 원 표본의 결측값을 D개의 대치된 표본을 만드므로 항상 같은 값으로 결측 자료를 대치할 수 없음\n",
    "        - 대치 : 베이지안 방법을 이용\n",
    "        - 분석 : D개의 대치표본으로부 원하는 분석을 각각 수행함\n",
    "        - 결합 : 모수(θ)의 점 추정과 표준오차의 추정치를 D개 구한후 이들을 결합하여 하나의 결과를 제시\n",
    "        \n",
    "### 데이터 이상값 처리 \n",
    "\n",
    "1. 데이터 이상값(Data Oultier)의 개념  \n",
    "  데이터의 범위에서 많이 벗어난 아주 작은 값이나 아주 큰 값이다.\n",
    "\n",
    "\n",
    "2. 데이터 이상값 발생 원인\n",
    "    - 표본추출 오류 : 데이터 샘플링 과정에서 발생하는 오류\n",
    "    - 고의적인 이상값 : 자기 보고식 측정에서 나타나는 오류\n",
    "    - 데이터 입력 오류 : 데이터를 수집하는 과정에서 발생할 수 있는 오류\n",
    "    - 실험 오류 : 실험 조건이 동일하지 않는 경우\n",
    "    - 측정 오류 : 측정하는 과정에서 발생한 오류\n",
    "    - 데이터 처리 오류 : 여러개의 데이터에서 필요한 데이터를 추출하거나 조합하여 사용하는 경우\n",
    "    - 자연 오류 : 자연스럽게 발생하는 오류\n",
    "\n",
    "\n",
    "3. 데이터 이상값 검출 방법\n",
    "- ESD : 평균($\\mu$)으로 부터 3 표준편차($\\sigma$) 떨어진 값(각 0.15%)을 이상값으로 판단, $\\mu - 3\\sigma < data < \\mu + 3\\sigma$\n",
    "- 기하평균을 활용한 방법 : 기하평균으로부터 2.5 표준편차($\\sigma$) 떨어진 값을 이상값으로 판단\n",
    "- 사분위수를 이용한 방법 : $Q_1 - 1.5(Q3-Q1) < data < Q_1 + 1.5(Q3-Q1)$\n",
    "- 표준화 점수(Z-score)를 활용한 방법 : 평균이 이고, 표준편차가 인 정규분포를 따른 관측값들이 평균에서 얼마나 떨어있는지 나타냄\n",
    "- 딕슨의 Q 검정 : 오름차순으로 정렬된 데이터에서 범위에 대한 관측치 간의 차이 비율 확인\n",
    "- 그럽스 T-검정 : 정규분포를 만족하는 단변량 자료에서 이상값 겁정\n",
    "- 카이제곱 검정 : 데이터가 정규분포를 만족하나, 자료의 수가 적은 경우에 이상값을 검정\n",
    "- 시각화를 이용한 데이터 이상값 검출 : Time Series plot, Boxplot, Histogram으로 확인\n",
    "- 머신러닝 기법을 이용한 이상값 검출 : 주어진 데이터를 K개의 클러스터(K-Clustering)로 묶는 알고리즘.\n",
    "- 마할라노비스 거리를 활용한 이상값 탐색 : 관측치가 평균으로부터 벗어난 정도를 측정하는 통계량\n",
    "- LOF : 관측치 주변의 밀도와 근접한 관측치 주변의 밀도의 상대적인 비교\n",
    "- iForest : 의사결정나무를 이용하여 이상값을 탐지하는 방법\n",
    "\n",
    "\n",
    "4. 데이터 이상값 처리\n",
    "- 삭제 : 이상값으로 판단되는 관측값을 제외하고 분석하는 방법. 양 극단의 값을 절단 한다.\n",
    "- 대체법 : 하한값보다 작으면 하한값으로 대체하고, 상한값보다 크면 상한값으로 대체한다.\n",
    "- 변환 : 자연로그를 취해서 값을 감소시키는 방법으로 실제값을 변형한다.\n",
    "\n",
    "## 분석 변수 처리 \n",
    "\n",
    "### 변수 선택 \n",
    "\n",
    "1. 변수(Feature) 개념\n",
    "    - 데이터 모델에서 사용하는 예측을 수행하는데 사용되는 입력변수.\n",
    "    - 알려진 값 : 변수(Feature), 속성(Attribute), 예측변수(Predictor), 차원(Dimension), 관측치(Observation), 독립변수(Independent)\n",
    "    - 예측 값 : 라벨(Label), 클래스(Class), 목표값(Target), 반응(Response), 종속변수(Dependent)\n",
    "\n",
    "\n",
    "2. 변수 유형\n",
    "    - 독립변수 : 다른 변수에 영향을 받지 않고 종속변수에 영향을 주는 변수\n",
    "    - 종속변수 : 다른 변수로부터 영향을 받는 변수\n",
    "\n",
    "\n",
    "3. 변수 선택  \n",
    "데이터의 독립변수($x$) 중 종속변수($y$)에 가장 관련성이 높은 변수만을 선정하는 방법. 변수 선택은 모델을 단순화 해주고 훈련시간 축소, 차원의 저주 방지, 과적합을 줄여 일반화를 해준다.\n",
    "\n",
    "\n",
    "4. 변수 선택 기법\n",
    "    - 필터 기법 : 통계적 측정 방법을 사용하여 변수(Feature) 들의 상관관계를 알아낸다\n",
    "        - 정보소득(Information Gain) : 가장 정보 소득이 높은 속성을 선택하여 데이터를 구분\n",
    "        - 카이제곱 검정(Chi-Square Test) : 관찰된 빈도가 기대대는 빈도와 의미있게 다른지 여부를 검정\n",
    "        - 피셔 스코어(Fisher Score) : 최대 가능성 방정식을 풀기위해 사용\n",
    "        - 상관계수(Correlation Coeeficient) : 두 변수 사이의 통계적 관계 표현\n",
    "    - 래퍼 기법 : 에측 정확도 면에서 가장 좋은 하위 집합(변수 묶음)을 선택하는 것. 그리디 알고리즘에 속하며 반복하여 선택하므로 시간이 오래걸리고 과적합의 위험이 발생할 수 있다.\n",
    "        - 전진 선택법 : 모형을 가장 향상시키는 변수를 하나씩 점진적으로 추가함\n",
    "        - 후진 선택법 : 모두 포함된 상태에서 시작하여 가장 적은 영향을 주는 변수를 제거\n",
    "        - 단계적 방법 : 전진 선택 + 후진선택\n",
    "        - RPE : SVM을 사용하여 재귀적으로 제거함\n",
    "        - SFS : 그리디 알고리즘으로 빈 부분 집합에서 특성변수를 하나씩 추가\n",
    "        - 유전 알고리즘 : 자연세계의 진화과정에 기초한 모델\n",
    "        - 단변량 선택 : 하나의 변수선택법\n",
    "        - mRMR : 특성 변수의 중복성을 최소화하는 방법으로, 독립변수들과도 중복성이 적은 변수를 선택\n",
    "    - 임베디드 기법 : 모델의 정확도에 기여하는 변수 학습. 모델 자체 내장되어 있음.\n",
    "        - 라쏘 : 가중치의 절댓값의 합을 최소화함. L1-norm을 통해 제약을 줌.\n",
    "        - 릿지 : 가중치의 제곱합을 최소화함. L2-norm을 통해 제약을 줌.\n",
    "        - 엘라스틱 넷 : 가중치의 절댓값의 함과 제곱합을 추가적으로 제약함. 라쏘 + 릿지\n",
    "        - SelectFromModel : 의사결정나무 기반 알고리즘에서 변수를 선택\n",
    "\n",
    "### 차원 축소 \n",
    "\n",
    "1. 차원축소(Dimensionality Reduction) 개념  \n",
    "분석 대상이 되는 여러 변수의 정보를 최대한 유지하면서 데이터 세트 변수의 개수를 줄이는 탐색적 분석기법.\n",
    "\n",
    "\n",
    "2. 차원축소 특징\n",
    "    - 축약되는 변수 세트는 원래의 전체 데이터의 변수들의 정보를 최대한 유지해야 한다.\n",
    "    - 다른 분석과정을 위한 전 단계, 분석 수행 후 개선 방법, 효과적인 시각화 등의 목적으로 사용된다.\n",
    "    - 저차원 변수 공간에서 가시적으로 시각화 하기도 쉽다.\n",
    "\n",
    "\n",
    "3. 차원축소 기법\n",
    "    - 주성분 분석(PCA) : 공분산 행렬이나 상관행렬을 이용한다. 정방행렬에서만 사용\n",
    "    - 특이값 분석(SVD) : 차원의 행렬데이터에서 특이값을 추출하여 사용\n",
    "    - 요인분석 : 데이터 안에 관찰할 수 없는 잠재적인 변수가 존재한다고 가정. 해당 잠재요인을 추출하여 구조를 해석함\n",
    "    - 독립성분분석 : 다변량의 신호를 통계적으로 독립적인 하부성분으로 분리하여 차원을 축소함\n",
    "    - 다차원 척도법 : 개체들 사이의 유사성 비유사성을 측정하여 시각적으로 표현함\n",
    "\n",
    "### 파생변수 생성 \n",
    "\n",
    "1. 파생변수 개념  \n",
    "기존 변수에 특정 조건 혹은 함수들을 사용하여 새롭게 재정의한 변수이다. 논리적 타당성과 기준을 가지고 생성하여야 한다.\n",
    "\n",
    "\n",
    "2. 파생변수 생성방법\n",
    "    - 단위 변환 : 주어진 변수의 단위 혹은 척도를 변환하여 새로운 단위로 표현\n",
    "    - 표현형식 변환 : 남/여 -> 0/1\n",
    "    - 요약 통게량 변환 : 고객별 누적 방문횟수 집계\n",
    "    - 정보 추출 : 하나의 변수에서 정보를 추출하여 새로운 변수 생성\n",
    "    - 변수 결합 : 수학적 결합을 통해 새로운 변수 정의\n",
    "    - 조건문 이용 : True/False 파생\n",
    "\n",
    "### 변순 변환 \n",
    "\n",
    "1. 변수 변환  \n",
    "분석을 위해 불필요한 변수를 제거하고, 변수를 반환하며, 새로운 변수를 생성시키는 작업\n",
    "\n",
    "\n",
    "2. 변수 변환 방법\n",
    "    - 단순 기능 변환 : 한쪽으로 치우친 변수를 변환함\n",
    "    - 로그 : 오른쪽으로 기울어진 것을 감소\n",
    "    - 제곱/세제곱/루트 변환\n",
    "    - 비닝 : 데이터 값을 몇개의 Bin으로 분할하여 계산하는 방법. 비즈니스 도메인 지식이 필요하며 데이터 평활화에도 사용\n",
    "    - 정규화 : 데이터를 특정 구간으로 바꾸는 척도법.\n",
    "    - 표준화 : 데이터를 0을 기준으로 양쪽으로 데이터를 분포시키는 방법.\n",
    "\n",
    "### 불균형 데이터 처리 \n",
    "\n",
    "1. 불균형 데이터 처리\n",
    "    - 과소 표집 : 다수 클래스의 데이터를 일부만 선택하여 데이터의 비율을 맞추는 방법. 데이터의 소실이 매우 크고, 정상 데이터를 잃을 수 있음.\n",
    "        - 랜덤 과소 표집 : 무작위로 다수 클래스 데이터의 일부만 선택\n",
    "        - ENN : 소수 클래스 주위에 인접한 다수 클래스 데이터를 제거 1. 불균형 데이터 처리\n",
    "    - 과소 표집 : 다수 클래스의 데이터를 일부만 선택하여 데이터의 비율을 맞추는 방법. 데이터의 소실이 매우 크고, 정상 데이터를 잃을 수 있음.\n",
    "        - 랜덤 과소 표집 : 무작위로 다수 클래스 데이터의 일부만 선택\n",
    "        - ENN : 소수 클래스 주위에 인접한 다수 클래스 데이터를 제거\n",
    "        - 토멕 링크 방법 : 클래스를 구분하는 경계선 가까이에 존재하는 데이터를 제거\n",
    "        - CNN : 다수 클래스에 밀집한 데이터가 없을 때까지 제거\n",
    "        - OSS : 토멕 링크 방법 + CNN 혼합 사용\n",
    "    - 과대 표집 : 소수 클래스의 데이터를 복제 또는 생성하여 데이터의 비율을 맞추는 방법. 과적합을 초래 할 수 있음.\n",
    "        - 랜덤 과대 표집 : 무작위로 소수 클래스 데이터를 복제함\n",
    "        - SMOTE : 소수 클래스에서 중심이 되는 데이터와 주번 데이터 사이에 가상의 직선을 만든 후 그 위에 데이터를 추가함\n",
    "        - Borderline-SMOTE : 다수 클래스와 소수 클래서 경계선에 SMOTE를 적용하는 방법\n",
    "        - ADASYN : 소수 클래스에서 다수 클래스의 관측 비율을 계산하여 SMTOE를 적용하는 방법.\n",
    "    - 임계값 이동 : 임계값을 데이터가 많은 쪽으로 이동시키는 방법\n",
    "    - 앙상블 기법 : 여러가지 모형들의 에측/분류 결과를 종합하여 최종적인 의사결정에 활용하는 기법.\n",
    "        - 토멕 링크 방법 : 클래스를 구분하는 경계선 가까이에 존재하는 데이터를 제거\n",
    "        - CNN : 다수 클래스에 밀집한 데이터가 없을 때까지 제거\n",
    "        - OSS : 토멕 링크 방법 + CNN 혼합 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d1277",
   "metadata": {},
   "source": [
    "# 데이터 탐색 \n",
    "\n",
    "## 데이터 탐색 기초 \n",
    "\n",
    "### 데이터 탐색 개요 \n",
    "\n",
    "1. 탐색적 데이터 분석(EDA) 개념  \n",
    "수집한 데이터를 분석하기 전에 그래프나 통계적인 방법으로 이용하여 다양한 각도에서 데이터의 특징을 파악하고 자료를 직관적으로 바라보는 분석 방법.\n",
    "\n",
    "\n",
    "2. EDA 특징\n",
    "    - 저항성 : 수집된 자료에 오류점, 이상값이 있을 떄도 영향을 적게 받는 성질, 데이터의 부분적 변동에 민감하게 반응하지 않음\n",
    "    - 잔차 해석 : 관촬 값들이 주 경향으로부터 얼마나 벗어난 정도. 데이터의 보통과 다른 특징을 탐색\n",
    "    - 자료 재표현 : 데이터 분석과 해석을 단순화할 수 있도록 원래 변수를 적당한 척도로 바꾸는 것. 분포의 대칭성, 선형성, 안정성 등 구조파악과 해석에 도움이 됨.\n",
    "    - 현시성 : 데이터 분석 결과를 쉽게 이해할 수 있도록 시각적으로 표현하고 전달하는 과정을 의미함.\n",
    "\n",
    "3. 개별 변수 탐색 방법\n",
    "    - 범주형 데이터(Categorical) : 빈도수, 최빈수, 비율, 백분율 등을 이용하여 파악\n",
    "    - 명목척도 : 관측 대상을 범주로 나누어 분류한 후 기호나 숫자를 부여함\n",
    "    - 순위척도 : 여러 관측 대상을 적당한 기준에 따라 비교 및 순위화함\n",
    "    - 수치형 데이터(Numerical) : 평균, 분산, 표준편차, 첨도, 왜도 등을 이용하여 파악\n",
    "    - 연속형 : 구간 안의 모든 값을 가질 수 있는 경우\n",
    "    - 이산형 : 취할 수 있는 값을 하나하나 셀 수 있는 경우\n",
    "\n",
    "\n",
    "4. 다차원 데이터 탐색 방법\n",
    "    - 범주형 vs 범주형 : 교차빈도, 비율, 백분율 분석등을 활용\n",
    "    - 수치형 vs 수치형 : 산점도와 기울기를 통해여 변수간의 상관성을 분석, 공분산을 이용하여 방향성 파악\n",
    "    - 범주형 vs 수치형 : 각 그룹에 따라 수치형 변수의 기술 통계량 차이를 상호 비교\n",
    "\n",
    "### 상관관계 분석 \n",
    "\n",
    "- 상관관계 분석  \n",
    "    - 두개 이상의 변수 사이에 존재하는 상호 연관성의 존재 여부와 연관성의 강도를 측정하여 분석하는 방법.\n",
    "    - 양의 상관관계 : r > 0.3\n",
    "    - 음의 상관관계 : r < -0.3\n",
    "    - 상관관계 없음 : -0.3 < r < 0.3\n",
    "\n",
    "### 기초통계량 추출 및 이해 \n",
    "\n",
    "- 중심 경향성의 통계량\n",
    "    - 평균값 : 자료를 모두 더한 후 자료 개수로 나누 값\n",
    "    - 중위수 : 모든 데이터 값을 순서대로 배열하였을 때 중앙에 위치한 데이터 값\n",
    "    - 최빈수 : 데이터값 중에서 빈도수가 가장 높은 데이터 값\n",
    "    - 사분위수 : 모든 데이터값을 순서대로 배열하였을 때 4등분 지점에 있는 값\n",
    "- 산포도 통계량\n",
    "    - 분산 : 평균으로부터 얼마나 떨어져 있는지를 나타내는 값\n",
    "    - 표준편차 : 분산에 양의 제곱근을 취한 값\n",
    "    - 범위 : 최댓값과 최솟값의 차\n",
    "    - IQR : 3분위수와 1분위수의 차이 값\n",
    "    - 사분편차 : IQR의 절반 값\n",
    "    - 변동계수 : 표준편차를 평균으로 나눈 값.\n",
    "- 분포 통계량\n",
    "    - 첨도 : 데이터 분포의 뾰족한 정도를 설명하는 통계량\n",
    "    - 왜도 : 데이터 분포의 기울어진 정도를 설명하는 통계량\n",
    "\n",
    "## 고급 데이터 탐색 \n",
    "\n",
    "### 시공간 데이터 탐색 \n",
    "\n",
    "1. 시공간 데이터  \n",
    "공간적 객체에 시간의 개념이 추가되어 시간에 따라 위치나 형상이 변하는 데이터\n",
    "\n",
    "\n",
    "2. 시공간 데이터 특징\n",
    "    - 이산적 변화 : 데이터 수집의 주기가 일정하지 않은 데이터를 이용하여 표현함\n",
    "    - 연속적 변화 : 일정한 주기로 수집되는 데이터를 이용하여 연속적으로 표현함\n",
    "\n",
    "\n",
    "3. 시공간 데이터 타입\n",
    "    - 포인트 타입 : 하나의 노드로 구성되는 공간 데이터 타입\n",
    "    - 라인 타입 : 서로 다른 두개의 노드와 두 노드를 잇는 하나의 세그먼트로 구성\n",
    "    - 폴리곤 타입 : n개의 노드와 n개의 세그먼트로 구성\n",
    "    - 폴리라인 타입 : n개의 노드와 n-1개의 세그먼트로 구성\n",
    "\n",
    "\n",
    "4. 행정구역 및 좌표계를 지도에 표시\n",
    "    - 코로플레스 지도 : 데이터 수치에 따라 지정한 색상 스케일로 영역을 색칠해서 표현하는 방법\n",
    "    - 카토그램 : 특정 데이터값의 변화에 따라 지도의 면적이 왜곡되는 지도로 변량 비례도라고 함. 시각적으로 더 크게 표시됨으로써 데이터값의 크기를 직관적으로 인지할 수 있음.\n",
    "    - 버블 플롯맵 : 버블차트에 위도와 경도 정보를 적용하여 좌표를 원으로 시각화한 지도\n",
    "\n",
    "### 다변량 데이터 탐색 \n",
    "\n",
    "1. 다변량 데이터의 유형\n",
    "    - 일변량 데이터 : 단위에 대해 하나의 속성만 측정하여 얻게되는 변수에 대한 자료\n",
    "    - 이변량 데이터 : 각 단위에 대해 두개의 특성을 측정하여 얻어진 두개의 변수에 대한 자료\n",
    "    - 다변량 데이터 : 하나의 단위에 대해 두가지 이상의 특성을 측정하는 경우 얻어지는 변수에 대한 자료\n",
    "\n",
    "\n",
    "2. 다변량 데이터 탐색\n",
    "    - 일변량 데이터 탐색 : 기술통계량(평균, 분산, 표준편차), 그래프 통계량(히스토그램, 상자그림)을 이용\n",
    "    - 이변량 데이터 탐색 : 조사 대상의 각 개체로부터 두개의 특성을 동시에 관측함.\n",
    "    - 다변량 데이터 탐색 : 산점도 행렬, 별 그림, 등고선 그림 등을 통해 시각적으로 자료를 탐색함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03eabd3",
   "metadata": {},
   "source": [
    "# 통계기법 이해 \n",
    "\n",
    "## 기술통계 \n",
    "\n",
    "### 데이터 요약 \n",
    "\n",
    "1. 데이터 요약\n",
    "    - 평균값 : 자료를 모두 더한 후 자료 개수로 나눈 값이다. 전부 같은 가중치를 두며 이상값에 민감하다.\n",
    "$$모평균 : \\mu = \\frac{1}{N}\\sum^{N}_{i=1}X_i$$\n",
    "$$표본평균 : \\mu = \\frac{1}{n}\\sum^{n}_{i=1}X_i$$\n",
    "\n",
    "    - 중위수 : 모든 데이터값을 오름차순으로 숫서대로 배열하였을 때 중앙에 위치한 데이터 값이다. 이상치에 영향을 받지 않는다\n",
    "$$d_{median} = \\frac{n+1}{2}번째 값$$    \n",
    "    - 최빈수 : 데이터 값 중에서 빈도수가 가장 높은 데이터 값이다\n",
    "    - 사분위수 : 모든 데이터값을 순서대로 배열하였을때 4등분한 지점에 있는 값이다. 0.5 quantile은 median이다.\n",
    "\n",
    "\n",
    "2. 산포도\n",
    "    - 분산 : 평균으로부터 얼마나 떨어져 있는지를 나타내는 값이다.\n",
    "$$모분산 : \\sigma^2 = \\frac{\\sum^{N}_{i=1}(X_i - \\mu)^2}{N}$$\n",
    "$$표본분산 : \\s^2 = \\frac{\\sum^{n}_{n=1}(X_i - \\mu)^2}{(n-1)}$$\n",
    "    - 표준편차 : 분산에 양의 제곱근을 취한 값.\n",
    "    - 범위 : 최댓값과 최솟값의 차이다.\n",
    "$$R = X_{max} - X_{min}$$\n",
    "    - IQR : 제3 사분위수와 제1 사분위수의 차이이다\n",
    "    - 사분편차 : IQR의 절반값이다.\n",
    "    - 변동계수 : 표준편차를 평균으로 나눈값이다. 측정 단위가 서로다른 자료의 흩어진 정도를 상대적으로 비교할 때 사용한다.\n",
    "\n",
    "\n",
    "3. 데이터 분포\n",
    "    - 첨도 : 데이터 분포의 '뾰족한 정도'를 설명하는 통계량이다.\n",
    "        - 첨도 > 0 : 뾰족함\n",
    "        - 첨도 < 0 : 완만함\n",
    "    - 왜도 : 데이터 분포의 '기울어진 정도'를 설명하는 통계량이다.\n",
    "        - 왜도 > 0 : 우측으로 긴 꼬리, 최빈수 < 중위수 < 평균\n",
    "        - 왜도 < 0 : 왼쪽으로 긴 꼬리, 최빈수 > 중위수 > 평균\n",
    "\n",
    "\n",
    "4. 공분산 : 2개의 변수 사이의 관련성을 나타내는 통계량이다.\n",
    "$$Cov(X, Y) = \\sigma_{XY} = \\frac{1}{N}\\sum^{N}_{i=1}(X_i - \\mu_x)(Y_i - \\mu_y)$$\n",
    "    - 공분산 > 0 : 양의 상관관계\n",
    "    - 공분산 < 0 : 음의 상관관계\n",
    "\n",
    "\n",
    "5. 상관계수 : 두 변수 사이에 어떤 선형적 또는 비선형적 관계가 있는지를 분석하는 방법. 두 변수 사이의 연관성을 수치상으로 객관화하여 두 변수 사이의 방향성과 강도를 표현하는 방법이다.\n",
    "    - 변수 속성에 따른 분류\n",
    "        - 수치적 데이터 : 피어슨 상관계수\n",
    "        - 순서적 데이터 : 스피어만 상관계수\n",
    "        - 명목적 데이터 : 카이제곱 검정\n",
    "\n",
    "### 표본 추출 \n",
    "\n",
    "1. 표본 추출  \n",
    "모집단 일부를 일정한 방법에 따라 표본으로 선택하는 과정\n",
    "\n",
    "\n",
    "2. 표본 추출 종류\n",
    "    - 단순 무작위 추출 : 모집단에서 정해진 규칙 없이 표본을 추출하는 방식\n",
    "    - 계통 추출 : 일정한 간격으로 추출하는 방식\n",
    "    - 층화 추출 : 모집단을 여러 계측으로 나누고, 계층별로 무작위 추출을 수행하는 방식. 층내는 동질적이고, 층간은 이질적이다.\n",
    "    - 군집 추출 : 모집단을 여러 군집으로 나누고, 일부 군집의 전체를 추출하는 방식. 집단 내부는 이질적이고, 집단 외부는 동질적이다.\n",
    "\n",
    "### 표본분포 \n",
    "\n",
    "1. 최대 우도법 : 어떤 확률변수에서 표집한 값을 토대로 그 확률변수의 모수를 구하는 방법\n",
    "$$L(\\theta)=  lnf_\\theta(x_1) + lnf_\\theta(x_2) + ...$$\n",
    "$$\\frac{\\sigma}{\\sigma\\theta}L(\\theta) = 0 인 값을 구한다.$$\n",
    "\n",
    "\n",
    "2. 표본분포  \n",
    "모집단에서 추출한 일정한 개수의 표본에 대한 분포 상태이다.\n",
    "\n",
    "\n",
    "3. 표본분포 용어\n",
    "    - 모집단 : 정보를 얻고자 하는 대상이 되는 집단 전체\n",
    "    - 모수 : 모집단의 특성을 나타내는 대푯값\n",
    "    - 통계량 : 표본에서 얻은 평균이나 표준편차 같은 값\n",
    "    - 추정량 : 모수의 추정을 위해 구해진 통계량\n",
    "    - 표본오차 : 모집단을 대표할 수 있는 표본 단위들이 조사대상으로 추출되지 못하기 때문에 발생하는 오차\n",
    "    - 비표본오차 : 표본오차를 제외한 모든 오차로서 조사 과정에서 발생하는 모든 부주의나 실수, 알수 없는 오차를 포함\n",
    "    - 표본편의 : 모수를 작게 또는 크게 할 때 추정하는 것과 같이 표본추출방법에서 기인하는 오차\n",
    "    - 큰수의 법칙 : 데이터를 많이 뽑을수록 표본평균의 분산은 0에 가까워짐\n",
    "    - 중심 극한 정리 : 데이터의 크기가 커지면 데이터 표본의 분포는 최종적으로 정규분포를 따름\n",
    "\n",
    "## 추론통계 \n",
    "\n",
    "### 추정 \n",
    "\n",
    "1. 추론통계\n",
    "    - 추론통계는 모집단의 표본을 가지고 모집단의 특성을 추론하고 그 결과의 신뢰성을 검정하는 통계적 방법\n",
    "    - 표본의 개수가 많을수록 표본오차는 감소한다\n",
    "    - 일부의 데이터를 이용하여 추정하므로 어느 정도의 오차가 있다.\n",
    "    - 점추정과 구간추정으로 구분된다.\n",
    "\n",
    "\n",
    "2. 점추정 : 모집단의 모수를 하나의 값으로 추정하는 기법이다.\n",
    "    - 불편성/불편의성 : 추정량의 기댓값이 모집단의 모수와 차이가 없음\n",
    "    - 효율성 : 추정량의 분산이 작을수록 좋음\n",
    "    - 일치성 : 표본의 크기가 아주 커지면, 추정량이 모수와 거의 같아짐(일치추정량)\n",
    "    - 충족성/충분성 : 모수에 대하여 많은 정보를 제공할수록 좋음(충분통계량)\n",
    "\n",
    "\n",
    "3. 구간추정 : 신뢰도를 제시하면서 범위로 모수를 추정하는 방법. 구해진 구간안에 모수가 있을 확률이 주어짐.\n",
    "    - 신뢰수준 : 추정값이 존재하는 구간에 모수가 포함될 확률. $100 \\times (1-\\alpha)$% 로 계산함\n",
    "    - 신뢰구간 : 신뢰수준을 기준으로 추정된 통계적으로 유의미한 모수의 범위.\n",
    "    \n",
    "    \n",
    "4. 표본의 크기 결정\n",
    "$$ n \\req (Z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{d})^2$$\n",
    "\n",
    "### 가설검정 \n",
    "\n",
    "1. 가설\n",
    "    - 귀무가설($H_0$) : 현재까지 주장되어 온 것이거나 기존과 비교하여 변화 혹은 차이가 없음을 나타내는 가설\n",
    "    - 대립가설($H_1$) : 표본을 통해 확실한 근거를 가지고 입증하고자 하는 가설\n",
    "\n",
    "\n",
    "2. 가설검정  \n",
    "모집단에 대한 통계적 가설을 세우고 표본을 추출한 다음, 그 표본을 통해 얻은 정보를 이용하여 통계적 가설의 진위를 판단하는 과정.\n",
    "\n",
    "\n",
    "3. 가설검정 절차\n",
    "- 가설 설정 : 귀무가설과 대립가설 설정. 양측 검정, 좌우측 검정 결정\n",
    "- 유의수준 설정 : $\\alpha$설정\n",
    "- 검정통계량 계산\n",
    "- 검정통계량 > 임곗값, p-value < 유의수준 비교 : 귀무가설 기각여부 확인\n",
    "\n",
    "\n",
    "4. 가설검정 오류의 종류\n",
    "- 제1종 오류 : 귀무가설이 참인데 이를 기각하게 되는 오류\n",
    "- 제2종 오류 : 귀무가설이 참이 아닐 때 이를 채택하게 되는 오류\n",
    "\n",
    "![](가설검정.png)\n",
    "\n",
    "||H_0|H_1|\n",
    "|:---:|:---:|:---:|\n",
    "|H_0|올바른 결정|제2종 오류|\n",
    "|H_1|제1종 오류|올바른 결정| \n",
    "\n",
    "- 검정통계량 : 가설검정의 대상이 되는 모수를 추론하기 위해 사용되는 표본 통계량 \n",
    "- p-value : 귀무가설이 참이라는 전제하에 실제 표본에서 구한 통계량의 값보다 더 극단적인 값이 나올 확률"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
